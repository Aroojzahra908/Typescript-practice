{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-05-04T18:00:09.630624Z",
     "iopub.status.busy": "2024-05-04T18:00:09.630209Z",
     "iopub.status.idle": "2024-05-04T18:00:10.849895Z",
     "shell.execute_reply": "2024-05-04T18:00:10.848489Z",
     "shell.execute_reply.started": "2024-05-04T18:00:09.630590Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/emnist/emnist-letters-mapping.txt\n",
      "/kaggle/input/emnist/emnist-letters-test.csv\n",
      "/kaggle/input/emnist/emnist-mnist-mapping.txt\n",
      "/kaggle/input/emnist/emnist-digits-train.csv\n",
      "/kaggle/input/emnist/emnist-bymerge-mapping.txt\n",
      "/kaggle/input/emnist/emnist-balanced-train.csv\n",
      "/kaggle/input/emnist/emnist-digits-test.csv\n",
      "/kaggle/input/emnist/emnist-balanced-test.csv\n",
      "/kaggle/input/emnist/emnist-mnist-test.csv\n",
      "/kaggle/input/emnist/emnist-letters-train.csv\n",
      "/kaggle/input/emnist/emnist-byclass-train.csv\n",
      "/kaggle/input/emnist/emnist-bymerge-test.csv\n",
      "/kaggle/input/emnist/emnist-balanced-mapping.txt\n",
      "/kaggle/input/emnist/emnist-mnist-train.csv\n",
      "/kaggle/input/emnist/emnist-digits-mapping.txt\n",
      "/kaggle/input/emnist/emnist-bymerge-train.csv\n",
      "/kaggle/input/emnist/emnist-byclass-test.csv\n",
      "/kaggle/input/emnist/emnist-byclass-mapping.txt\n",
      "/kaggle/input/emnist/emnist_source_files/emnist-digits-test-labels-idx1-ubyte\n",
      "/kaggle/input/emnist/emnist_source_files/emnist-bymerge-train-labels-idx1-ubyte\n",
      "/kaggle/input/emnist/emnist_source_files/emnist-letters-test-labels-idx1-ubyte\n",
      "/kaggle/input/emnist/emnist_source_files/emnist-byclass-train-images-idx3-ubyte\n",
      "/kaggle/input/emnist/emnist_source_files/emnist-byclass-test-images-idx3-ubyte\n",
      "/kaggle/input/emnist/emnist_source_files/emnist-mnist-train-images-idx3-ubyte\n",
      "/kaggle/input/emnist/emnist_source_files/emnist-digits-train-labels-idx1-ubyte\n",
      "/kaggle/input/emnist/emnist_source_files/emnist-bymerge-test-images-idx3-ubyte\n",
      "/kaggle/input/emnist/emnist_source_files/emnist-bymerge-test-labels-idx1-ubyte\n",
      "/kaggle/input/emnist/emnist_source_files/emnist-mnist-test-labels-idx1-ubyte\n",
      "/kaggle/input/emnist/emnist_source_files/emnist-balanced-test-labels-idx1-ubyte\n",
      "/kaggle/input/emnist/emnist_source_files/emnist-balanced-test-images-idx3-ubyte\n",
      "/kaggle/input/emnist/emnist_source_files/emnist-mnist-test-images-idx3-ubyte\n",
      "/kaggle/input/emnist/emnist_source_files/emnist-bymerge-train-images-idx3-ubyte\n",
      "/kaggle/input/emnist/emnist_source_files/emnist-letters-train-labels-idx1-ubyte\n",
      "/kaggle/input/emnist/emnist_source_files/emnist-digits-train-images-idx3-ubyte\n",
      "/kaggle/input/emnist/emnist_source_files/emnist-byclass-train-labels-idx1-ubyte\n",
      "/kaggle/input/emnist/emnist_source_files/emnist-balanced-train-images-idx3-ubyte\n",
      "/kaggle/input/emnist/emnist_source_files/emnist-balanced-train-labels-idx1-ubyte\n",
      "/kaggle/input/emnist/emnist_source_files/emnist-letters-test-images-idx3-ubyte\n",
      "/kaggle/input/emnist/emnist_source_files/emnist-byclass-test-labels-idx1-ubyte\n",
      "/kaggle/input/emnist/emnist_source_files/emnist-letters-train-images-idx3-ubyte\n",
      "/kaggle/input/emnist/emnist_source_files/emnist-mnist-train-labels-idx1-ubyte\n",
      "/kaggle/input/emnist/emnist_source_files/emnist-digits-test-images-idx3-ubyte\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-04T18:00:38.111888Z",
     "iopub.status.busy": "2024-05-04T18:00:38.111301Z",
     "iopub.status.idle": "2024-05-04T18:00:52.870899Z",
     "shell.execute_reply": "2024-05-04T18:00:52.869533Z",
     "shell.execute_reply.started": "2024-05-04T18:00:38.111844Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-04 18:00:40.347205: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-05-04 18:00:40.347353: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-05-04 18:00:40.508504: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-04T18:01:05.461585Z",
     "iopub.status.busy": "2024-05-04T18:01:05.460449Z",
     "iopub.status.idle": "2024-05-04T18:01:19.755532Z",
     "shell.execute_reply": "2024-05-04T18:01:19.754309Z",
     "shell.execute_reply.started": "2024-05-04T18:01:05.461544Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   label  1  2  3  4  5  6  7  8  9  ...  775  776  777  778  779  780  781  \\\n",
      "0     45  0  0  0  0  0  0  0  0  0  ...    0    0    0    0    0    0    0   \n",
      "1     36  0  0  0  0  0  0  0  0  0  ...    0    0    0    0    0    0    0   \n",
      "2     43  0  0  0  0  0  0  0  0  0  ...    0    0    0    0    0    0    0   \n",
      "3     15  0  0  0  0  0  0  0  0  0  ...    0    0    0    0    0    0    0   \n",
      "4      4  0  0  0  0  0  0  0  0  0  ...    0    0    0    0    0    0    0   \n",
      "\n",
      "   782  783  784  \n",
      "0    0    0    0  \n",
      "1    0    0    0  \n",
      "2    0    0    0  \n",
      "3    0    0    0  \n",
      "4    0    0    0  \n",
      "\n",
      "[5 rows x 785 columns]\n",
      "   label  1  2  3  4  5  6  7  8  9  ...  775  776  777  778  779  780  781  \\\n",
      "0     41  0  0  0  0  0  0  0  0  0  ...    0    0    0    0    0    0    0   \n",
      "1     39  0  0  0  0  0  0  0  0  0  ...    0    0    0    0    0    0    0   \n",
      "2      9  0  0  0  0  0  0  0  0  0  ...    0    0    0    0    0    0    0   \n",
      "3     26  0  0  0  0  0  0  0  0  0  ...    0    0    0    0    0    0    0   \n",
      "4     44  0  0  0  0  0  0  0  0  0  ...    0    0    0    0    0    0    0   \n",
      "\n",
      "   782  783  784  \n",
      "0    0    0    0  \n",
      "1    0    0    0  \n",
      "2    0    0    0  \n",
      "3    0    0    0  \n",
      "4    0    0    0  \n",
      "\n",
      "[5 rows x 785 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "num_columns = 785\n",
    "\n",
    "# Create column names\n",
    "columns = ['label'] + list(range(1, num_columns))\n",
    "\n",
    "# Read the training and testing datasets\n",
    "ds_train = pd.read_csv(\"/kaggle/input/emnist/emnist-balanced-train.csv\", header=None)\n",
    "ds_test = pd.read_csv(\"/kaggle/input/emnist/emnist-balanced-test.csv\", header=None)\n",
    "\n",
    "# Assign column names to the DataFrames\n",
    "ds_train.columns = columns\n",
    "ds_test.columns = columns\n",
    "\n",
    "# Reset index\n",
    "ds_train = ds_train.reset_index(drop=True)\n",
    "ds_test = ds_test.reset_index(drop=True)\n",
    "\n",
    "# Extract features and labels\n",
    "x_train = ds_train.drop(['label'], axis=1)\n",
    "y_train = ds_train['label']\n",
    "x_test = ds_test.drop(['label'], axis=1)\n",
    "y_test = ds_test['label']\n",
    "\n",
    "# Display the first few rows of the DataFrame\n",
    "print(ds_train.head())\n",
    "print(ds_test.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-04T18:01:27.928647Z",
     "iopub.status.busy": "2024-05-04T18:01:27.927231Z",
     "iopub.status.idle": "2024-05-04T18:01:27.939075Z",
     "shell.execute_reply": "2024-05-04T18:01:27.937943Z",
     "shell.execute_reply.started": "2024-05-04T18:01:27.928558Z"
    }
   },
   "outputs": [],
   "source": [
    "alpha_num_to_char = {\n",
    "    0: '0', 1: '1', 2: '2', 3: '3', 4: '4', 5: '5', 6: '6', 7: '7', 8: '8', 9: '9',\n",
    "    10: 'a', 11: 'b', 12: 'c', 13: 'd', 14: 'e', 15: 'f', 16: 'g', 17: 'h', 18: 'i', 19: 'j',\n",
    "    20: 'k', 21: 'l', 22: 'm', 23: 'n', 24: 'o', 25: 'p', 26: 'q', 27: 'r', 28: 's', 29: 't',\n",
    "    30: 'u', 31: 'v', 32: 'w', 33: 'x', 34: 'y', 35: 'z',\n",
    "    36: 'A', 37: 'B', 38: 'C', 39: 'D', 40: 'E', 41: 'F', 42: 'G', 43: 'H', 44: 'I', 45: 'J',\n",
    "    46: 'K', 47: 'L', 48: 'M', 49: 'N', 50: 'O', 51: 'P', 52: 'Q', 53: 'R', 54: 'S', 55: 'T',\n",
    "    56: 'U', 57: 'V', 58: 'W', 59: 'X', 60: 'Y', 61: 'Z'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-04T18:01:36.523303Z",
     "iopub.status.busy": "2024-05-04T18:01:36.522871Z",
     "iopub.status.idle": "2024-05-04T18:01:36.529897Z",
     "shell.execute_reply": "2024-05-04T18:01:36.528662Z",
     "shell.execute_reply.started": "2024-05-04T18:01:36.523261Z"
    }
   },
   "outputs": [],
   "source": [
    "def show_example(n) :\n",
    "    label = alpha_num_to_char[ds_train.iloc[n,0]]  # the example's label\n",
    "    plt.title(label)\n",
    "    example = np.array(x_train.iloc[n]) # extract the 28 *28 array that contains the pixels\n",
    "    example_image = example.reshape(28 , 28 ) # rearrange the array to be a 28 by 28 matrix ,that represents that actual image\n",
    "    plt.imshow(example_image , cmap ='gray')\n",
    "    plt.axis('off')\n",
    "  \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-04T18:01:46.259029Z",
     "iopub.status.busy": "2024-05-04T18:01:46.258555Z",
     "iopub.status.idle": "2024-05-04T18:01:46.266543Z",
     "shell.execute_reply": "2024-05-04T18:01:46.265220Z",
     "shell.execute_reply.started": "2024-05-04T18:01:46.258994Z"
    }
   },
   "outputs": [],
   "source": [
    "def show_example_and_predicted_val(n,predicted_n) :\n",
    "\n",
    "    true_val = alpha_num_to_char[ds_train.iloc[n,0]]  # the example's label\n",
    "    predicted_val = alpha_num_to_char[predicted_n]  # the example's label\n",
    "    \n",
    "    plt.title(\"Actual val : \"+ true_val+\"\\n Predicted :\" + predicted_val)\n",
    "    example = np.array(x_train.iloc[n]) # extract the 28 *28 array that contains the pixels\n",
    "    example_image = example.reshape(28 , 28 ) # rearrange the array to be a 28 by 28 matrix ,that represents that actual image\n",
    "    plt.imshow(example_image , cmap ='gray')\n",
    "    plt.axis('off')\n",
    "  \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-04T18:01:56.719509Z",
     "iopub.status.busy": "2024-05-04T18:01:56.719116Z",
     "iopub.status.idle": "2024-05-04T18:01:56.872687Z",
     "shell.execute_reply": "2024-05-04T18:01:56.871479Z",
     "shell.execute_reply.started": "2024-05-04T18:01:56.719482Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_example(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-04T18:02:08.428918Z",
     "iopub.status.busy": "2024-05-04T18:02:08.427929Z",
     "iopub.status.idle": "2024-05-04T18:02:10.827989Z",
     "shell.execute_reply": "2024-05-04T18:02:10.826663Z",
     "shell.execute_reply.started": "2024-05-04T18:02:08.428877Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "class Reshaper(BaseEstimator, TransformerMixin):\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        X_reshaped = X.reshape(-1, 28, 28, 1)\n",
    "        return X_reshaped\n",
    "\n",
    "# Define the pipeline\n",
    "pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),  # Step 1: StandardScaler\n",
    "    ('reshaper', Reshaper())  # Step 2: Custom Reshaper\n",
    "])\n",
    "\n",
    "\n",
    "# Fit and transform the training data\n",
    "\n",
    "x_train_processed = pipeline.fit_transform(x_train)\n",
    "y_train_processed = np.eye(62)[y_train.astype(int)]\n",
    "\n",
    "x_test_processed = pipeline.transform(x_test)\n",
    "\n",
    "y_test_processed = np.eye(62)[y_test.astype(int)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-04T18:02:20.261058Z",
     "iopub.status.busy": "2024-05-04T18:02:20.260514Z",
     "iopub.status.idle": "2024-05-04T18:02:20.270181Z",
     "shell.execute_reply": "2024-05-04T18:02:20.267180Z",
     "shell.execute_reply.started": "2024-05-04T18:02:20.261001Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input shape (112800, 28, 28, 1)\n",
      "output shape (112800,)\n",
      "output shape (112800, 62)\n"
     ]
    }
   ],
   "source": [
    "print('input shape',x_train_processed.shape)\n",
    "print('output shape',y_train.shape)\n",
    "# y_train = np.eye(62)[y_train.astype(int)]\n",
    "print('output shape',y_train_processed.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-04T18:02:35.120065Z",
     "iopub.status.busy": "2024-05-04T18:02:35.119535Z",
     "iopub.status.idle": "2024-05-04T18:22:46.871229Z",
     "shell.execute_reply": "2024-05-04T18:22:46.869809Z",
     "shell.execute_reply.started": "2024-05-04T18:02:35.120024Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/keras/src/layers/convolutional/base_conv.py:99: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m3525/3525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 15ms/step - accuracy: 0.6616 - loss: 1.1855\n",
      "Epoch 2/5\n",
      "\u001b[1m3525/3525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 14ms/step - accuracy: 0.8350 - loss: 0.5008\n",
      "Epoch 3/5\n",
      "\u001b[1m3525/3525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 14ms/step - accuracy: 0.8542 - loss: 0.4232\n",
      "Epoch 4/5\n",
      "\u001b[1m3525/3525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 14ms/step - accuracy: 0.8682 - loss: 0.3785\n",
      "Epoch 5/5\n",
      "\u001b[1m3525/3525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 14ms/step - accuracy: 0.8767 - loss: 0.3420\n",
      "Epoch 1/5\n",
      "\u001b[1m3525/3525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 18ms/step - accuracy: 0.5292 - loss: 1.6774\n",
      "Epoch 2/5\n",
      "\u001b[1m3525/3525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 18ms/step - accuracy: 0.7446 - loss: 0.8072\n",
      "Epoch 3/5\n",
      "\u001b[1m3525/3525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 18ms/step - accuracy: 0.7716 - loss: 0.7195\n",
      "Epoch 4/5\n",
      "\u001b[1m3525/3525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 18ms/step - accuracy: 0.7852 - loss: 0.6635\n",
      "Epoch 5/5\n",
      "\u001b[1m3525/3525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 18ms/step - accuracy: 0.7945 - loss: 0.6300\n",
      "Epoch 1/5\n",
      "\u001b[1m3525/3525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 23ms/step - accuracy: 0.5752 - loss: 1.4839\n",
      "Epoch 2/5\n",
      "\u001b[1m3525/3525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 23ms/step - accuracy: 0.7817 - loss: 0.6692\n",
      "Epoch 3/5\n",
      "\u001b[1m3525/3525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 23ms/step - accuracy: 0.8052 - loss: 0.5869\n",
      "Epoch 4/5\n",
      "\u001b[1m3525/3525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 24ms/step - accuracy: 0.8185 - loss: 0.5415\n",
      "Epoch 5/5\n",
      "\u001b[1m3525/3525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 23ms/step - accuracy: 0.8279 - loss: 0.4982\n",
      "\u001b[1m588/588\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.8494 - loss: 0.5152\n",
      "Model 1 Accuracy: 0.8477127552032471\n",
      "\u001b[1m588/588\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.8385 - loss: 0.5072\n",
      "Model 2 Accuracy: 0.8377659320831299\n",
      "\u001b[1m588/588\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.8525 - loss: 0.4448\n",
      "Model 3 Accuracy: 0.8507446646690369\n",
      "Best Model: Model 3\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten, Conv2D, MaxPooling2D,Dropout\n",
    "\n",
    "#  multiple model architectures\n",
    "models = []\n",
    "input_shape=(28,28,1)\n",
    "# Model 1\n",
    "model1 = Sequential()\n",
    "model1.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=input_shape))\n",
    "model1.add(MaxPooling2D((2, 2)))\n",
    "model1.add(Flatten())\n",
    "model1.add(Dense(128, activation='relu'))\n",
    "model1.add(Dense(62, activation='softmax'))\n",
    "models.append(model1)\n",
    "\n",
    "# Model 2\n",
    "model2 = Sequential()\n",
    "model2.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=input_shape))\n",
    "model2.add(Dropout(0.25)) \n",
    "model2.add(MaxPooling2D((2, 2)))\n",
    "model2.add(Flatten())\n",
    "model2.add(Dense(128, activation='relu'))\n",
    "model2.add(Dropout(0.4))\n",
    "model2.add(Dense(62, activation='softmax'))\n",
    "# Add layers for Model 2\n",
    "models.append(model2)\n",
    "\n",
    "# Model 3\n",
    "model3 = Sequential()\n",
    "model3.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=input_shape))\n",
    "model3.add(Dropout(0.25)) \n",
    "model3.add(MaxPooling2D((2, 2)))\n",
    "model3.add(Flatten())\n",
    "model3.add(Dense(256, activation='relu'))\n",
    "model3.add(Dropout(0.4))\n",
    "model3.add(Dense(128, activation='relu'))\n",
    "model3.add(Dense(62, activation='softmax'))\n",
    "models.append(model3)\n",
    "\n",
    "# Train each model\n",
    "for i, model in enumerate(models):\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    model.fit(x_train_processed, y_train_processed, epochs=5, batch_size=32)\n",
    "\n",
    "# Evaluate each model\n",
    "accuracies = []\n",
    "for i, model in enumerate(models):\n",
    "    loss, accuracy = model.evaluate(x_test_processed, y_test_processed)\n",
    "    accuracies.append(accuracy)\n",
    "    print(f\"Model {i+1} Accuracy: {accuracy}\")\n",
    "\n",
    "# Select the best model based on accuracy\n",
    "best_model_index = accuracies.index(max(accuracies))\n",
    "best_model = models[best_model_index]\n",
    "print(f\"Best Model: Model {best_model_index+1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-04T18:23:33.924229Z",
     "iopub.status.busy": "2024-05-04T18:23:33.923781Z",
     "iopub.status.idle": "2024-05-04T18:23:33.997012Z",
     "shell.execute_reply": "2024-05-04T18:23:33.995806Z",
     "shell.execute_reply.started": "2024-05-04T18:23:33.924194Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-04T18:24:52.354798Z",
     "iopub.status.busy": "2024-05-04T18:24:52.354336Z",
     "iopub.status.idle": "2024-05-04T18:24:52.361102Z",
     "shell.execute_reply": "2024-05-04T18:24:52.359895Z",
     "shell.execute_reply.started": "2024-05-04T18:24:52.354761Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Function to load the model on your machine\n",
    "def load_my_model(filepath):\n",
    "    model = load_model(\"best_emnist_model.h5\")\n",
    "    model.predict(filepath)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = \"pic1.png\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow\n",
      "  Using cached tensorflow-2.16.1-cp39-cp39-win_amd64.whl (2.1 kB)\n",
      "Collecting tensorflow-intel==2.16.1\n",
      "  Using cached tensorflow_intel-2.16.1-cp39-cp39-win_amd64.whl (376.9 MB)\n",
      "Collecting gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1\n",
      "  Using cached gast-0.5.4-py3-none-any.whl (19 kB)\n",
      "Collecting libclang>=13.0.0\n",
      "  Using cached libclang-18.1.1-py2.py3-none-win_amd64.whl (26.4 MB)\n",
      "Collecting tensorflow-io-gcs-filesystem>=0.23.1\n",
      "  Using cached tensorflow_io_gcs_filesystem-0.31.0-cp39-cp39-win_amd64.whl (1.5 MB)\n",
      "Collecting keras>=3.0.0\n",
      "  Using cached keras-3.3.3-py3-none-any.whl (1.1 MB)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\farha\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (4.11.0)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in c:\\users\\farha\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (1.26.4)\n",
      "Requirement already satisfied: setuptools in c:\\users\\farha\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (58.0.4)\n",
      "Requirement already satisfied: packaging in c:\\users\\farha\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (24.0)\n",
      "Collecting h5py>=3.10.0\n",
      "  Using cached h5py-3.11.0-cp39-cp39-win_amd64.whl (3.0 MB)\n",
      "Collecting tensorboard<2.17,>=2.16\n",
      "  Using cached tensorboard-2.16.2-py3-none-any.whl (5.5 MB)\n",
      "Collecting termcolor>=1.1.0\n",
      "  Using cached termcolor-2.4.0-py3-none-any.whl (7.7 kB)\n",
      "Collecting grpcio<2.0,>=1.24.3\n",
      "  Using cached grpcio-1.63.0-cp39-cp39-win_amd64.whl (3.9 MB)\n",
      "Collecting ml-dtypes~=0.3.1\n",
      "  Using cached ml_dtypes-0.3.2-cp39-cp39-win_amd64.whl (127 kB)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\farha\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (1.16.0)\n",
      "Collecting absl-py>=1.0.0\n",
      "  Using cached absl_py-2.1.0-py3-none-any.whl (133 kB)\n",
      "Collecting flatbuffers>=23.5.26\n",
      "  Using cached flatbuffers-24.3.25-py2.py3-none-any.whl (26 kB)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\farha\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (1.12.1)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in c:\\users\\farha\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (3.20.3)\n",
      "Collecting astunparse>=1.6.0\n",
      "  Using cached astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Collecting opt-einsum>=2.3.2\n",
      "  Using cached opt_einsum-3.3.0-py3-none-any.whl (65 kB)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\farha\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (2.26.0)\n",
      "Collecting google-pasta>=0.1.1\n",
      "  Using cached google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\farha\\anaconda3\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.16.1->tensorflow) (0.37.0)\n",
      "Collecting namex\n",
      "  Using cached namex-0.0.8-py3-none-any.whl (5.8 kB)\n",
      "Collecting optree\n",
      "  Using cached optree-0.11.0-cp39-cp39-win_amd64.whl (240 kB)\n",
      "Requirement already satisfied: rich in c:\\users\\farha\\anaconda3\\lib\\site-packages (from keras>=3.0.0->tensorflow-intel==2.16.1->tensorflow) (13.7.1)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\farha\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.16.1->tensorflow) (2.0.4)"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: The script markdown_py.exe is installed in 'C:\\Users\\farha\\AppData\\Roaming\\Python\\Python39\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The script tensorboard.exe is installed in 'C:\\Users\\farha\\AppData\\Roaming\\Python\\Python39\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The scripts import_pb_to_tensorboard.exe, saved_model_cli.exe, tensorboard.exe, tf_upgrade_v2.exe, tflite_convert.exe, toco.exe and toco_from_protos.exe are installed in 'C:\\Users\\farha\\AppData\\Roaming\\Python\\Python39\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\farha\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.16.1->tensorflow) (1.26.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\farha\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.16.1->tensorflow) (2021.10.8)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\farha\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.16.1->tensorflow) (3.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\farha\\anaconda3\\lib\\site-packages (from tensorboard<2.17,>=2.16->tensorflow-intel==2.16.1->tensorflow) (2.0.2)\n",
      "Collecting markdown>=2.6.8\n",
      "  Using cached Markdown-3.6-py3-none-any.whl (105 kB)\n",
      "Collecting tensorboard-data-server<0.8.0,>=0.7.0\n",
      "  Using cached tensorboard_data_server-0.7.2-py3-none-any.whl (2.4 kB)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in c:\\users\\farha\\anaconda3\\lib\\site-packages (from markdown>=2.6.8->tensorboard<2.17,>=2.16->tensorflow-intel==2.16.1->tensorflow) (4.8.1)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\farha\\anaconda3\\lib\\site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.17,>=2.16->tensorflow-intel==2.16.1->tensorflow) (3.6.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\farha\\anaconda3\\lib\\site-packages (from rich->keras>=3.0.0->tensorflow-intel==2.16.1->tensorflow) (2.17.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\farha\\anaconda3\\lib\\site-packages (from rich->keras>=3.0.0->tensorflow-intel==2.16.1->tensorflow) (3.0.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\farha\\anaconda3\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.0.0->tensorflow-intel==2.16.1->tensorflow) (0.1.2)\n",
      "Installing collected packages: tensorboard-data-server, optree, namex, ml-dtypes, markdown, h5py, grpcio, absl-py, termcolor, tensorflow-io-gcs-filesystem, tensorboard, opt-einsum, libclang, keras, google-pasta, gast, flatbuffers, astunparse, tensorflow-intel, tensorflow\n",
      "Successfully installed absl-py-2.1.0 astunparse-1.6.3 flatbuffers-24.3.25 gast-0.5.4 google-pasta-0.2.0 grpcio-1.63.0 h5py-3.11.0 keras-3.3.3 libclang-18.1.1 markdown-3.6 ml-dtypes-0.3.2 namex-0.0.8 opt-einsum-3.3.0 optree-0.11.0 tensorboard-2.16.2 tensorboard-data-server-0.7.2 tensorflow-2.16.1 tensorflow-intel-2.16.1 tensorflow-io-gcs-filesystem-0.31.0 termcolor-2.4.0\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow --user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step\n",
      "Predicted Digit: 36\n"
     ]
    }
   ],
   "source": [
    "# from tensorflow.keras.models import load_model\n",
    "# from PIL import Image\n",
    "# import numpy as np\n",
    "# import pandas as pd \n",
    "# # Load the best model\n",
    "# best_model = load_model('best_emnist_model.h5')\n",
    "\n",
    "# # Load the new image\n",
    "# new_image = Image.open('pic2.png')\n",
    "\n",
    "# # Preprocess the new image\n",
    "# new_image = new_image.resize((28, 28))\n",
    "# new_image = new_image.convert('L')\n",
    "# new_image_array = np.array(new_image)\n",
    "# new_image_array = new_image_array / 255.0\n",
    "\n",
    "# # Make predictions\n",
    "# predictions = best_model.predict(new_image_array.reshape((1, 28, 28, 1)))\n",
    "\n",
    "# # Get the predicted digit (index with highest probability)\n",
    "# predicted_digit = np.argmax(predictions)\n",
    "\n",
    "# print(\"Predicted Digit:\", predicted_digit)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 5 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x00000222FCAD6310> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 5 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x00000222FCAD6310> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step\n",
      "Predicted Letter: b\n"
     ]
    }
   ],
   "source": [
    "alpha_num_to_char = {\n",
    "    0: '0',\n",
    "    1: '1',\n",
    "    2: '2',\n",
    "    3: '3',\n",
    "    4: '4',\n",
    "    5: '5',\n",
    "    6: '6',\n",
    "    7: '7',\n",
    "    8: '8',\n",
    "    9: '9',\n",
    "    10: 'a',\n",
    "    11: 'b',\n",
    "    12: 'c',\n",
    "    13: 'd',\n",
    "    14: 'e',\n",
    "    15: 'f',\n",
    "    16: 'g',\n",
    "    17: 'h',\n",
    "    18: 'i',\n",
    "    19: 'j',\n",
    "    20: 'k',\n",
    "    21: 'l',\n",
    "    22: 'm',\n",
    "    23: 'n',\n",
    "    24: 'o',\n",
    "    25: 'p',\n",
    "    26: 'q',\n",
    "    27: 'r',\n",
    "    28: 's',\n",
    "    29: 't',\n",
    "    30: 'u',\n",
    "    31: 'v',\n",
    "    32: 'w',\n",
    "    33: 'x',\n",
    "    34: 'y',\n",
    "    35: 'z',\n",
    "    36: 'A',\n",
    "    37: 'B',\n",
    "    38: 'C',\n",
    "    39: 'D',\n",
    "    40: 'E',\n",
    "    41: 'F',\n",
    "    42: 'G',\n",
    "    43: 'H',\n",
    "    44: 'I',\n",
    "    45: 'J',\n",
    "    46: 'K',\n",
    "    47: 'L',\n",
    "    48: 'M',\n",
    "    49: 'N',\n",
    "    50: 'O',\n",
    "    51: 'P',\n",
    "    52: 'Q',\n",
    "    53: 'R',\n",
    "    54: 'S',\n",
    "    55: 'T',\n",
    "    56: 'U',\n",
    "    57: 'V',\n",
    "    58: 'W',\n",
    "    59: 'X',\n",
    "    60: 'Y',\n",
    "    61: 'Z'\n",
    "}\n",
    "\n",
    "# Load the necessary libraries and load the trained model\n",
    "from tensorflow.keras.models import load_model\n",
    "from PIL import Image\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "\n",
    "best_model = load_model('best_emnist_model.h5')\n",
    "\n",
    "# Load and preprocess the new image\n",
    "new_image = Image.open('pic2.png')\n",
    "new_image = new_image.resize((28, 28))\n",
    "new_image = new_image.convert('L')\n",
    "scaler = StandardScaler()\n",
    "new_image_array = np.array(new_image)\n",
    "new_image_array = scaler.fit_transform(new_image_array.reshape(-1, 1)).reshape(28, 28)\n",
    "\n",
    "# Reshape the image array to fit the model input shape\n",
    "new_image_array = new_image_array.reshape(1, 28, 28, 1)\n",
    "\n",
    "# Make predictions on the new image\n",
    "predictions = best_model.predict(new_image_array)\n",
    "\n",
    "# Get the predicted digit (index with highest probability)\n",
    "predicted_digit = np.argmax(predictions)\n",
    "predicted_letter = alpha_num_to_char[predicted_digit]\n",
    "\n",
    "# Print the predicted digit\n",
    "print(\"Predicted Letter:\", predicted_letter)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 7160,
     "sourceId": 10705,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30698,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
