{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in c:\\users\\arooj zahra\\anaconda3\\envs\\gpu_env\\lib\\site-packages (2.6.0+cu118)\n",
      "Requirement already satisfied: transformers in c:\\users\\arooj zahra\\anaconda3\\envs\\gpu_env\\lib\\site-packages (4.48.3)\n",
      "Requirement already satisfied: accelerate in c:\\users\\arooj zahra\\anaconda3\\envs\\gpu_env\\lib\\site-packages (1.3.0)\n",
      "Requirement already satisfied: bitsandbytes in c:\\users\\arooj zahra\\anaconda3\\envs\\gpu_env\\lib\\site-packages (0.45.2)\n",
      "Requirement already satisfied: peft in c:\\users\\arooj zahra\\anaconda3\\envs\\gpu_env\\lib\\site-packages (0.14.0)\n",
      "Requirement already satisfied: pdfplumber in c:\\users\\arooj zahra\\anaconda3\\envs\\gpu_env\\lib\\site-packages (0.11.5)\n",
      "Requirement already satisfied: datasets in c:\\users\\arooj zahra\\anaconda3\\envs\\gpu_env\\lib\\site-packages (3.2.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\arooj zahra\\anaconda3\\envs\\gpu_env\\lib\\site-packages (from torch) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\arooj zahra\\anaconda3\\envs\\gpu_env\\lib\\site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: networkx in c:\\users\\arooj zahra\\anaconda3\\envs\\gpu_env\\lib\\site-packages (from torch) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\arooj zahra\\anaconda3\\envs\\gpu_env\\lib\\site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in c:\\users\\arooj zahra\\anaconda3\\envs\\gpu_env\\lib\\site-packages (from torch) (2024.6.1)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\arooj zahra\\anaconda3\\envs\\gpu_env\\lib\\site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\arooj zahra\\anaconda3\\envs\\gpu_env\\lib\\site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in c:\\users\\arooj zahra\\anaconda3\\envs\\gpu_env\\lib\\site-packages (from transformers) (0.28.1)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\arooj zahra\\anaconda3\\envs\\gpu_env\\lib\\site-packages (from transformers) (1.26.3)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\arooj zahra\\anaconda3\\envs\\gpu_env\\lib\\site-packages (from transformers) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\arooj zahra\\anaconda3\\envs\\gpu_env\\lib\\site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\arooj zahra\\anaconda3\\envs\\gpu_env\\lib\\site-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in c:\\users\\arooj zahra\\anaconda3\\envs\\gpu_env\\lib\\site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in c:\\users\\arooj zahra\\anaconda3\\envs\\gpu_env\\lib\\site-packages (from transformers) (0.21.0)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in c:\\users\\arooj zahra\\anaconda3\\envs\\gpu_env\\lib\\site-packages (from transformers) (0.5.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\arooj zahra\\anaconda3\\envs\\gpu_env\\lib\\site-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: psutil in c:\\users\\arooj zahra\\anaconda3\\envs\\gpu_env\\lib\\site-packages (from accelerate) (6.1.1)\n",
      "Requirement already satisfied: pdfminer.six==20231228 in c:\\users\\arooj zahra\\anaconda3\\envs\\gpu_env\\lib\\site-packages (from pdfplumber) (20231228)\n",
      "Requirement already satisfied: Pillow>=9.1 in c:\\users\\arooj zahra\\anaconda3\\envs\\gpu_env\\lib\\site-packages (from pdfplumber) (11.0.0)\n",
      "Requirement already satisfied: pypdfium2>=4.18.0 in c:\\users\\arooj zahra\\anaconda3\\envs\\gpu_env\\lib\\site-packages (from pdfplumber) (4.30.1)\n",
      "Requirement already satisfied: charset-normalizer>=2.0.0 in c:\\users\\arooj zahra\\anaconda3\\envs\\gpu_env\\lib\\site-packages (from pdfminer.six==20231228->pdfplumber) (3.4.1)\n",
      "Requirement already satisfied: cryptography>=36.0.0 in c:\\users\\arooj zahra\\anaconda3\\envs\\gpu_env\\lib\\site-packages (from pdfminer.six==20231228->pdfplumber) (44.0.1)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in c:\\users\\arooj zahra\\anaconda3\\envs\\gpu_env\\lib\\site-packages (from datasets) (19.0.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in c:\\users\\arooj zahra\\anaconda3\\envs\\gpu_env\\lib\\site-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: pandas in c:\\users\\arooj zahra\\anaconda3\\envs\\gpu_env\\lib\\site-packages (from datasets) (2.2.3)\n",
      "Requirement already satisfied: xxhash in c:\\users\\arooj zahra\\anaconda3\\envs\\gpu_env\\lib\\site-packages (from datasets) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in c:\\users\\arooj zahra\\anaconda3\\envs\\gpu_env\\lib\\site-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: aiohttp in c:\\users\\arooj zahra\\anaconda3\\envs\\gpu_env\\lib\\site-packages (from datasets) (3.11.12)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in c:\\users\\arooj zahra\\anaconda3\\envs\\gpu_env\\lib\\site-packages (from aiohttp->datasets) (2.4.6)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\arooj zahra\\anaconda3\\envs\\gpu_env\\lib\\site-packages (from aiohttp->datasets) (1.3.2)\n",
      "Requirement already satisfied: async-timeout<6.0,>=4.0 in c:\\users\\arooj zahra\\anaconda3\\envs\\gpu_env\\lib\\site-packages (from aiohttp->datasets) (5.0.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\arooj zahra\\anaconda3\\envs\\gpu_env\\lib\\site-packages (from aiohttp->datasets) (25.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\arooj zahra\\anaconda3\\envs\\gpu_env\\lib\\site-packages (from aiohttp->datasets) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\arooj zahra\\anaconda3\\envs\\gpu_env\\lib\\site-packages (from aiohttp->datasets) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in c:\\users\\arooj zahra\\anaconda3\\envs\\gpu_env\\lib\\site-packages (from aiohttp->datasets) (0.2.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in c:\\users\\arooj zahra\\anaconda3\\envs\\gpu_env\\lib\\site-packages (from aiohttp->datasets) (1.18.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\arooj zahra\\anaconda3\\envs\\gpu_env\\lib\\site-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\arooj zahra\\anaconda3\\envs\\gpu_env\\lib\\site-packages (from requests->transformers) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\arooj zahra\\anaconda3\\envs\\gpu_env\\lib\\site-packages (from requests->transformers) (2025.1.31)\n",
      "Requirement already satisfied: colorama in c:\\users\\arooj zahra\\anaconda3\\envs\\gpu_env\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\arooj zahra\\anaconda3\\envs\\gpu_env\\lib\\site-packages (from jinja2->torch) (2.1.5)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\arooj zahra\\anaconda3\\envs\\gpu_env\\lib\\site-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\arooj zahra\\anaconda3\\envs\\gpu_env\\lib\\site-packages (from pandas->datasets) (2025.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\arooj zahra\\anaconda3\\envs\\gpu_env\\lib\\site-packages (from pandas->datasets) (2025.1)\n",
      "Requirement already satisfied: cffi>=1.12 in c:\\users\\arooj zahra\\anaconda3\\envs\\gpu_env\\lib\\site-packages (from cryptography>=36.0.0->pdfminer.six==20231228->pdfplumber) (1.17.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\arooj zahra\\anaconda3\\envs\\gpu_env\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
      "Requirement already satisfied: pycparser in c:\\users\\arooj zahra\\anaconda3\\envs\\gpu_env\\lib\\site-packages (from cffi>=1.12->cryptography>=36.0.0->pdfminer.six==20231228->pdfplumber) (2.22)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install torch transformers accelerate bitsandbytes peft pdfplumber datasets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA Available: True\n",
      "GPU Name: NVIDIA RTX A4000\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "cuda_path = r\"C:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v11.1\\bin\"\n",
    "cudnn_path = r\"C:\\Program Files\\NVIDIA Corporation\\cudnn\\v8.0\\bin\"\n",
    "\n",
    "# Add CUDA and cuDNN to PATH manually\n",
    "os.environ[\"PATH\"] = cuda_path + \";\" + cudnn_path + \";\" + os.environ[\"PATH\"]\n",
    "\n",
    "import torch\n",
    "print(\"CUDA Available:\", torch.cuda.is_available())\n",
    "print(\"GPU Name:\", torch.cuda.get_device_name(0) if torch.cuda.is_available() else \"No GPU detected\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "# Check if CUDA is available and use GPU if possible\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "%pip install unsloth\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: huggingface_hub in c:\\users\\arooj zahra\\anaconda3\\envs\\gpu_env\\lib\\site-packages (0.28.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\arooj zahra\\anaconda3\\envs\\gpu_env\\lib\\site-packages (from huggingface_hub) (3.13.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\arooj zahra\\anaconda3\\envs\\gpu_env\\lib\\site-packages (from huggingface_hub) (2024.6.1)\n",
      "Requirement already satisfied: packaging>=20.9 in c:\\users\\arooj zahra\\anaconda3\\envs\\gpu_env\\lib\\site-packages (from huggingface_hub) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\arooj zahra\\anaconda3\\envs\\gpu_env\\lib\\site-packages (from huggingface_hub) (6.0.2)\n",
      "Requirement already satisfied: requests in c:\\users\\arooj zahra\\anaconda3\\envs\\gpu_env\\lib\\site-packages (from huggingface_hub) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in c:\\users\\arooj zahra\\anaconda3\\envs\\gpu_env\\lib\\site-packages (from huggingface_hub) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\arooj zahra\\anaconda3\\envs\\gpu_env\\lib\\site-packages (from huggingface_hub) (4.12.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\arooj zahra\\anaconda3\\envs\\gpu_env\\lib\\site-packages (from tqdm>=4.42.1->huggingface_hub) (0.4.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\arooj zahra\\anaconda3\\envs\\gpu_env\\lib\\site-packages (from requests->huggingface_hub) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\arooj zahra\\anaconda3\\envs\\gpu_env\\lib\\site-packages (from requests->huggingface_hub) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\arooj zahra\\anaconda3\\envs\\gpu_env\\lib\\site-packages (from requests->huggingface_hub) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\arooj zahra\\anaconda3\\envs\\gpu_env\\lib\\site-packages (from requests->huggingface_hub) (2025.1.31)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "02803290dcb54535b0d685d8e438da42",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "!pip install huggingface_hub \n",
    "from huggingface_hub import notebook_login\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import login\n",
    "\n",
    "# Authenticate with your Hugging Face token\n",
    "login(\"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\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "%pip install -U transformers \n",
    "%pip install -U datasets \n",
    "%pip install -U accelerate \n",
    "%pip install -U peft \n",
    "%pip install -U trl \n",
    "%pip install -U bitsandbytes \n",
    "%pip install -U wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import (\n",
    "    AutoModelForCausalLM,\n",
    "    AutoTokenizer,\n",
    "    BitsAndBytesConfig,\n",
    "    HfArgumentParser,\n",
    "    TrainingArguments,\n",
    "    pipeline,\n",
    "    logging,\n",
    ")\n",
    "from peft import (\n",
    "    LoraConfig,\n",
    "    PeftModel,\n",
    "    prepare_model_for_kbit_training,\n",
    "    get_peft_model,\n",
    ")\n",
    "import os, torch, wandb\n",
    "from datasets import load_dataset\n",
    "from trl import SFTTrainer, setup_chat_format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logged in to Hugging Face successfully!\n"
     ]
    }
   ],
   "source": [
    "from huggingface_hub import login\n",
    "\n",
    "# Manually enter your Hugging Face token\n",
    "hf_token = \"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\"  # Replace this with your actual token\n",
    "\n",
    "login(token=hf_token)\n",
    "print(\"Logged in to Hugging Face successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: No netrc file found, creating one.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: C:\\Users\\Arooj zahra\\_netrc\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mzahraarooj373\u001b[0m (\u001b[33mzahraarooj373-financebuzz\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.7"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>d:\\AroojZahra_Project\\llama model\\wandb\\run-20250224_184959-9twk6jyp</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/zahraarooj373-financebuzz/Fine-tune%20Llama%203.2%20on%20Customer%20Support%20Dataset/runs/9twk6jyp?apiKey=7b93fe59e9994c6d3abe0a063876f67a7a283905' target=\"_blank\">ethereal-wood-1</a></strong> to <a href='https://wandb.ai/zahraarooj373-financebuzz/Fine-tune%20Llama%203.2%20on%20Customer%20Support%20Dataset?apiKey=7b93fe59e9994c6d3abe0a063876f67a7a283905' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/zahraarooj373-financebuzz/Fine-tune%20Llama%203.2%20on%20Customer%20Support%20Dataset?apiKey=7b93fe59e9994c6d3abe0a063876f67a7a283905' target=\"_blank\">https://wandb.ai/zahraarooj373-financebuzz/Fine-tune%20Llama%203.2%20on%20Customer%20Support%20Dataset?apiKey=7b93fe59e9994c6d3abe0a063876f67a7a283905</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/zahraarooj373-financebuzz/Fine-tune%20Llama%203.2%20on%20Customer%20Support%20Dataset/runs/9twk6jyp?apiKey=7b93fe59e9994c6d3abe0a063876f67a7a283905' target=\"_blank\">https://wandb.ai/zahraarooj373-financebuzz/Fine-tune%20Llama%203.2%20on%20Customer%20Support%20Dataset/runs/9twk6jyp?apiKey=7b93fe59e9994c6d3abe0a063876f67a7a283905</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Do NOT share these links with anyone. They can be used to claim your runs."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import wandb\n",
    "\n",
    "# Manually enter your W&B API key\n",
    "wb_token = \"7b93fe59e9994c6d3abe0a063876f67a7a283905\"  # Replace this with your actual token\n",
    "\n",
    "wandb.login(key=wb_token)\n",
    "run = wandb.init(\n",
    "    project='Fine-tune Llama 3.2 on Customer Support Dataset', \n",
    "    job_type=\"training\", \n",
    "    anonymous=\"allow\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = \"meta-llama/Llama-3.2-3B-Instruct\"\n",
    "new_model = \"llama-3.2-3b-it-wheat-ChatBot\"\n",
    "dataset_name = \"D:\\AroojZahra_Project\\llama model\\book_dataset.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set torch dtype and attention implementation\n",
    "if torch.cuda.get_device_capability()[0] >= 8:\n",
    "    !pip install -qqq flash-attn\n",
    "    torch_dtype = torch.bfloat16\n",
    "    attn_implementation = \"flash_attention_2\"\n",
    "else:\n",
    "    torch_dtype = torch.float16\n",
    "    attn_implementation = \"eager\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "384020996ddd4179b6aae7bbc9273680",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# QLoRA config\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=torch_dtype,\n",
    "    bnb_4bit_use_double_quant=True,\n",
    ")\n",
    "# Load model\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    base_model,\n",
    "    quantization_config=bnb_config,\n",
    "    device_map=\"auto\",\n",
    ")\n",
    "\n",
    "# Load tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(base_model, trust_remote_code=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pymupdf in c:\\users\\arooj zahra\\anaconda3\\envs\\gpu_env\\lib\\site-packages (1.25.3)\n",
      "Requirement already satisfied: datasets in c:\\users\\arooj zahra\\anaconda3\\envs\\gpu_env\\lib\\site-packages (3.3.2)\n",
      "Requirement already satisfied: pandas in c:\\users\\arooj zahra\\anaconda3\\envs\\gpu_env\\lib\\site-packages (2.2.3)\n",
      "Requirement already satisfied: filelock in c:\\users\\arooj zahra\\anaconda3\\envs\\gpu_env\\lib\\site-packages (from datasets) (3.13.1)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\arooj zahra\\anaconda3\\envs\\gpu_env\\lib\\site-packages (from datasets) (1.26.3)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in c:\\users\\arooj zahra\\anaconda3\\envs\\gpu_env\\lib\\site-packages (from datasets) (19.0.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in c:\\users\\arooj zahra\\anaconda3\\envs\\gpu_env\\lib\\site-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: requests>=2.32.2 in c:\\users\\arooj zahra\\anaconda3\\envs\\gpu_env\\lib\\site-packages (from datasets) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in c:\\users\\arooj zahra\\anaconda3\\envs\\gpu_env\\lib\\site-packages (from datasets) (4.67.1)\n",
      "Requirement already satisfied: xxhash in c:\\users\\arooj zahra\\anaconda3\\envs\\gpu_env\\lib\\site-packages (from datasets) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in c:\\users\\arooj zahra\\anaconda3\\envs\\gpu_env\\lib\\site-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2024.12.0,>=2023.1.0 in c:\\users\\arooj zahra\\anaconda3\\envs\\gpu_env\\lib\\site-packages (from fsspec[http]<=2024.12.0,>=2023.1.0->datasets) (2024.6.1)\n",
      "Requirement already satisfied: aiohttp in c:\\users\\arooj zahra\\anaconda3\\envs\\gpu_env\\lib\\site-packages (from datasets) (3.11.12)\n",
      "Requirement already satisfied: huggingface-hub>=0.24.0 in c:\\users\\arooj zahra\\anaconda3\\envs\\gpu_env\\lib\\site-packages (from datasets) (0.28.1)\n",
      "Requirement already satisfied: packaging in c:\\users\\arooj zahra\\anaconda3\\envs\\gpu_env\\lib\\site-packages (from datasets) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\arooj zahra\\anaconda3\\envs\\gpu_env\\lib\\site-packages (from datasets) (6.0.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\arooj zahra\\anaconda3\\envs\\gpu_env\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\arooj zahra\\anaconda3\\envs\\gpu_env\\lib\\site-packages (from pandas) (2025.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\arooj zahra\\anaconda3\\envs\\gpu_env\\lib\\site-packages (from pandas) (2025.1)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in c:\\users\\arooj zahra\\anaconda3\\envs\\gpu_env\\lib\\site-packages (from aiohttp->datasets) (2.4.6)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\arooj zahra\\anaconda3\\envs\\gpu_env\\lib\\site-packages (from aiohttp->datasets) (1.3.2)\n",
      "Requirement already satisfied: async-timeout<6.0,>=4.0 in c:\\users\\arooj zahra\\anaconda3\\envs\\gpu_env\\lib\\site-packages (from aiohttp->datasets) (5.0.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\arooj zahra\\anaconda3\\envs\\gpu_env\\lib\\site-packages (from aiohttp->datasets) (25.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\arooj zahra\\anaconda3\\envs\\gpu_env\\lib\\site-packages (from aiohttp->datasets) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\arooj zahra\\anaconda3\\envs\\gpu_env\\lib\\site-packages (from aiohttp->datasets) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in c:\\users\\arooj zahra\\anaconda3\\envs\\gpu_env\\lib\\site-packages (from aiohttp->datasets) (0.2.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in c:\\users\\arooj zahra\\anaconda3\\envs\\gpu_env\\lib\\site-packages (from aiohttp->datasets) (1.18.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\arooj zahra\\anaconda3\\envs\\gpu_env\\lib\\site-packages (from huggingface-hub>=0.24.0->datasets) (4.12.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\arooj zahra\\anaconda3\\envs\\gpu_env\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\arooj zahra\\anaconda3\\envs\\gpu_env\\lib\\site-packages (from requests>=2.32.2->datasets) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\arooj zahra\\anaconda3\\envs\\gpu_env\\lib\\site-packages (from requests>=2.32.2->datasets) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\arooj zahra\\anaconda3\\envs\\gpu_env\\lib\\site-packages (from requests>=2.32.2->datasets) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\arooj zahra\\anaconda3\\envs\\gpu_env\\lib\\site-packages (from requests>=2.32.2->datasets) (2025.1.31)\n",
      "Requirement already satisfied: colorama in c:\\users\\arooj zahra\\anaconda3\\envs\\gpu_env\\lib\\site-packages (from tqdm>=4.66.3->datasets) (0.4.6)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pymupdf datasets pandas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract text from PDF books\n",
    "import os\n",
    "from PyPDF2 import PdfReader\n",
    "import pandas as pd\n",
    "\n",
    "pdf_directory = \"D:/AroojZahra_Project/llama model/data\"  # Change this to your PDF folder\n",
    "book_data = []\n",
    "\n",
    "for filename in os.listdir(pdf_directory):\n",
    "    if filename.endswith('.pdf'):\n",
    "        file_path = os.path.join(pdf_directory, filename)\n",
    "        reader = PdfReader(file_path)\n",
    "        book_text = \"\"\n",
    "        for page in reader.pages:\n",
    "            book_text += page.extract_text() + \" \"\n",
    "        \n",
    "        # Split text into chunks (adjust chunk size as needed)\n",
    "        chunks = [book_text[i:i+1000] for i in range(0, len(book_text), 1000)]\n",
    "        \n",
    "        # Create instruction-response pairs\n",
    "        for i in range(len(chunks)-1):\n",
    "            book_data.append({\n",
    "                \"instruction\": f\"Continue this text from the book: {chunks[i]}\",\n",
    "                \"response\": chunks[i+1]\n",
    "            })\n",
    "\n",
    "# Convert to DataFrame and save\n",
    "book_df = pd.DataFrame(book_data)\n",
    "book_df.to_csv(\"book_dataset.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "16fc6cba74344de08fbb0ffa53b8ebb3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=4):   0%|          | 0/900 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "21d762afc1324af09e12bc645eaf2627",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=4):   0%|          | 0/100 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Define the instruction\n",
    "instruction = \"\"\"You are an AI trained on literary works.\n",
    "    Continue text passages in the style and content of these books.\n",
    "    \"\"\"\n",
    "\n",
    "# Modify your function to take both instruction and tokenizer as parameters\n",
    "def format_chat_template(row, instruction=None, tokenizer=None):\n",
    "    row_json = [{\"role\": \"system\", \"content\": instruction},\n",
    "               {\"role\": \"user\", \"content\": row[\"instruction\"]},\n",
    "               {\"role\": \"assistant\", \"content\": row[\"response\"]}]\n",
    "    \n",
    "    row[\"text\"] = tokenizer.apply_chat_template(row_json, tokenize=False)\n",
    "    return row\n",
    "\n",
    "# Map with both parameters\n",
    "dataset = dataset.map(\n",
    "    format_chat_template,\n",
    "    fn_kwargs={\"instruction\": instruction, \"tokenizer\": tokenizer},\n",
    "    num_proc=4,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
      "\n",
      "Cutting Knowledge Date: December 2023\n",
      "Today Date: 24 Feb 2025\n",
      "\n",
      "You are an AI trained on literary works.\n",
      "    Continue text passages in the style and content of these books.<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "Continue this text from the book: ed.\n",
      "Degradation of soil structure is most significant on the\n",
      "fine textured soils such as salmon gum/gimlet and moortsoils. These soils contain silt or fine sand in the surface andwhen cultivated too frequently or when too wet, slake, andform impermeable crusts.\n",
      "The physical degradation of some fine textured soils\n",
      "can mean that the soil is no longer able to absorb theincident rainfall; the soil surface becomes crusted and thesoil so dense that germination and root growth areimpeded. In order to maintain soil fertility and surfacestructural condition in an intensive cropping system, it isessential that tillage is reduced to a minimum and stubbleis retained. It is also desirable to incorporate a pasture phaseinto the cropping program. Pasture has been shown to havea highly beneficial effect on soil structural condition byincreasing aggregate stability through improved soilorganic matter content. \n",
      "On these (fine-textured) soils, improvement or\n",
      "maintenance of a porous surface structure is v<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "ital for cropproduction, which implies that organic matter should beaccumulated in the surface. Periods of pasture are the most\n",
      "biologically effective way of providing organic matter.\n",
      "New cropping techniques which reduce the loss of\n",
      "organic matter caused by tillage, are also effective inmaintaining or increasing soil organic matter andstructural stability in periods of cropping.\n",
      "An absence of ploughing or scarifying as well as\n",
      "conservation of crop stubbles, will reduce the loss oforganic matter by oxidation after cultivation and stubbleburning. Sowing with narrow points or discs (‘No-Till’)will also reduce loss of organic matter by oxidation andhelp conserve root channels.\n",
      "THE WHEAT BOOK CHAPTER 6 – W HEAT IN FARMING SYSTEMS\n",
      "117SOIL STRUCTURE\n",
      "Figure 6.5\n",
      "Pastures increase soil aggregate stability; cropping decreases\n",
      "aggregate stability Increases in soil organic matter should improve the\n",
      "moisture holding capacity of poorly textured sandplainsoils.\n",
      "It is possible that under pasture there<|eot_id|>\n"
     ]
    }
   ],
   "source": [
    "# Access the text column from a specific example\n",
    "print(dataset['train']['text'][3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bitsandbytes as bnb\n",
    "\n",
    "def find_all_linear_names(model):\n",
    "    cls = bnb.nn.Linear4bit\n",
    "    lora_module_names = set()\n",
    "    for name, module in model.named_modules():\n",
    "        if isinstance(module, cls):\n",
    "            names = name.split('.')\n",
    "            lora_module_names.add(names[0] if len(names) == 1 else names[-1])\n",
    "    if 'lm_head' in lora_module_names:  # needed for 16 bit\n",
    "        lora_module_names.remove('lm_head')\n",
    "    return list(lora_module_names)\n",
    "\n",
    "modules = find_all_linear_names(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LoRA config\n",
    "peft_config = LoraConfig(\n",
    "    r=16,\n",
    "    lora_alpha=32,\n",
    "    lora_dropout=0.05,\n",
    "    bias=\"none\",\n",
    "    task_type=\"CAUSAL_LM\",\n",
    "    target_modules=modules\n",
    ")\n",
    "\n",
    "# Skip the setup_chat_format call\n",
    "# model, tokenizer = setup_chat_format(model, tokenizer)  # Remove this line\n",
    "\n",
    "# Just get the PEFT model directly\n",
    "model = get_peft_model(model, peft_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hyperparamter\n",
    "training_arguments = TrainingArguments(\n",
    "    output_dir=new_model,\n",
    "    per_device_train_batch_size=1,\n",
    "    per_device_eval_batch_size=1,\n",
    "    gradient_accumulation_steps=2,\n",
    "    optim=\"paged_adamw_32bit\",\n",
    "    num_train_epochs=1,\n",
    "    eval_strategy=\"steps\",\n",
    "    eval_steps=0.2,\n",
    "    logging_steps=1,\n",
    "    warmup_steps=10,\n",
    "    logging_strategy=\"steps\",\n",
    "    learning_rate=2e-4,\n",
    "    fp16=False,\n",
    "    bf16=False,\n",
    "    group_by_length=True,\n",
    "    report_to=\"wandb\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(self, model: Union[str, torch.nn.modules.module.Module, transformers.modeling_utils.PreTrainedModel], args: Union[trl.trainer.sft_config.SFTConfig, transformers.training_args.TrainingArguments, NoneType] = None, data_collator: Optional[DataCollator] = None, train_dataset: Union[datasets.arrow_dataset.Dataset, datasets.iterable_dataset.IterableDataset, NoneType] = None, eval_dataset: Union[datasets.arrow_dataset.Dataset, dict[str, datasets.arrow_dataset.Dataset], NoneType] = None, processing_class: Union[transformers.tokenization_utils_base.PreTrainedTokenizerBase, transformers.image_processing_utils.BaseImageProcessor, transformers.feature_extraction_utils.FeatureExtractionMixin, transformers.processing_utils.ProcessorMixin, NoneType] = None, compute_loss_func: Optional[Callable] = None, compute_metrics: Optional[Callable[[transformers.trainer_utils.EvalPrediction], dict]] = None, callbacks: Optional[list[transformers.trainer_callback.TrainerCallback]] = None, optimizers: tuple[typing.Optional[torch.optim.optimizer.Optimizer], typing.Optional[torch.optim.lr_scheduler.LambdaLR]] = (None, None), optimizer_cls_and_kwargs: Optional[tuple[Type[torch.optim.optimizer.Optimizer], dict[str, Any]]] = None, preprocess_logits_for_metrics: Optional[Callable[[torch.Tensor, torch.Tensor], torch.Tensor]] = None, peft_config: Optional[ForwardRef('PeftConfig')] = None, formatting_func: Union[Callable[[dict], str], Callable[[dict], list[str]], NoneType] = None)\n"
     ]
    }
   ],
   "source": [
    "# Let's check what parameters SFTTrainer accepts\n",
    "from trl import SFTTrainer\n",
    "import inspect\n",
    "\n",
    "# Print the accepted parameters\n",
    "print(inspect.signature(SFTTrainer.__init__))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting trl==0.7.4\n",
      "  Downloading trl-0.7.4-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: torch>=1.4.0 in c:\\users\\arooj zahra\\anaconda3\\envs\\gpu_env\\lib\\site-packages (from trl==0.7.4) (2.6.0+cu118)\n",
      "Requirement already satisfied: transformers>=4.18.0 in c:\\users\\arooj zahra\\anaconda3\\envs\\gpu_env\\lib\\site-packages (from trl==0.7.4) (4.48.3)\n",
      "Requirement already satisfied: numpy>=1.18.2 in c:\\users\\arooj zahra\\anaconda3\\envs\\gpu_env\\lib\\site-packages (from trl==0.7.4) (1.26.3)\n",
      "Requirement already satisfied: accelerate in c:\\users\\arooj zahra\\anaconda3\\envs\\gpu_env\\lib\\site-packages (from trl==0.7.4) (1.4.0)\n",
      "Requirement already satisfied: datasets in c:\\users\\arooj zahra\\anaconda3\\envs\\gpu_env\\lib\\site-packages (from trl==0.7.4) (3.3.2)\n",
      "Collecting tyro>=0.5.11 (from trl==0.7.4)\n",
      "  Using cached tyro-0.9.16-py3-none-any.whl.metadata (9.4 kB)\n",
      "Requirement already satisfied: filelock in c:\\users\\arooj zahra\\anaconda3\\envs\\gpu_env\\lib\\site-packages (from torch>=1.4.0->trl==0.7.4) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\arooj zahra\\anaconda3\\envs\\gpu_env\\lib\\site-packages (from torch>=1.4.0->trl==0.7.4) (4.12.2)\n",
      "Requirement already satisfied: networkx in c:\\users\\arooj zahra\\anaconda3\\envs\\gpu_env\\lib\\site-packages (from torch>=1.4.0->trl==0.7.4) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\arooj zahra\\anaconda3\\envs\\gpu_env\\lib\\site-packages (from torch>=1.4.0->trl==0.7.4) (3.1.4)\n",
      "Requirement already satisfied: fsspec in c:\\users\\arooj zahra\\anaconda3\\envs\\gpu_env\\lib\\site-packages (from torch>=1.4.0->trl==0.7.4) (2024.6.1)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\arooj zahra\\anaconda3\\envs\\gpu_env\\lib\\site-packages (from torch>=1.4.0->trl==0.7.4) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\arooj zahra\\anaconda3\\envs\\gpu_env\\lib\\site-packages (from sympy==1.13.1->torch>=1.4.0->trl==0.7.4) (1.3.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in c:\\users\\arooj zahra\\anaconda3\\envs\\gpu_env\\lib\\site-packages (from transformers>=4.18.0->trl==0.7.4) (0.28.1)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\arooj zahra\\anaconda3\\envs\\gpu_env\\lib\\site-packages (from transformers>=4.18.0->trl==0.7.4) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\arooj zahra\\anaconda3\\envs\\gpu_env\\lib\\site-packages (from transformers>=4.18.0->trl==0.7.4) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\arooj zahra\\anaconda3\\envs\\gpu_env\\lib\\site-packages (from transformers>=4.18.0->trl==0.7.4) (2024.11.6)\n",
      "Requirement already satisfied: requests in c:\\users\\arooj zahra\\anaconda3\\envs\\gpu_env\\lib\\site-packages (from transformers>=4.18.0->trl==0.7.4) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in c:\\users\\arooj zahra\\anaconda3\\envs\\gpu_env\\lib\\site-packages (from transformers>=4.18.0->trl==0.7.4) (0.21.0)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in c:\\users\\arooj zahra\\anaconda3\\envs\\gpu_env\\lib\\site-packages (from transformers>=4.18.0->trl==0.7.4) (0.5.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\arooj zahra\\anaconda3\\envs\\gpu_env\\lib\\site-packages (from transformers>=4.18.0->trl==0.7.4) (4.67.1)\n",
      "Requirement already satisfied: colorama>=0.4.0 in c:\\users\\arooj zahra\\anaconda3\\envs\\gpu_env\\lib\\site-packages (from tyro>=0.5.11->trl==0.7.4) (0.4.6)\n",
      "Collecting docstring-parser>=0.15 (from tyro>=0.5.11->trl==0.7.4)\n",
      "  Using cached docstring_parser-0.16-py3-none-any.whl.metadata (3.0 kB)\n",
      "Requirement already satisfied: eval-type-backport>=0.1.3 in c:\\users\\arooj zahra\\anaconda3\\envs\\gpu_env\\lib\\site-packages (from tyro>=0.5.11->trl==0.7.4) (0.2.2)\n",
      "Requirement already satisfied: rich>=11.1.0 in c:\\users\\arooj zahra\\anaconda3\\envs\\gpu_env\\lib\\site-packages (from tyro>=0.5.11->trl==0.7.4) (13.9.4)\n",
      "Collecting shtab>=1.5.6 (from tyro>=0.5.11->trl==0.7.4)\n",
      "  Using cached shtab-1.7.1-py3-none-any.whl.metadata (7.3 kB)\n",
      "Collecting typeguard>=4.0.0 (from tyro>=0.5.11->trl==0.7.4)\n",
      "  Using cached typeguard-4.4.2-py3-none-any.whl.metadata (3.8 kB)\n",
      "Requirement already satisfied: psutil in c:\\users\\arooj zahra\\anaconda3\\envs\\gpu_env\\lib\\site-packages (from accelerate->trl==0.7.4) (6.1.1)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in c:\\users\\arooj zahra\\anaconda3\\envs\\gpu_env\\lib\\site-packages (from datasets->trl==0.7.4) (19.0.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in c:\\users\\arooj zahra\\anaconda3\\envs\\gpu_env\\lib\\site-packages (from datasets->trl==0.7.4) (0.3.8)\n",
      "Requirement already satisfied: pandas in c:\\users\\arooj zahra\\anaconda3\\envs\\gpu_env\\lib\\site-packages (from datasets->trl==0.7.4) (2.2.3)\n",
      "Requirement already satisfied: xxhash in c:\\users\\arooj zahra\\anaconda3\\envs\\gpu_env\\lib\\site-packages (from datasets->trl==0.7.4) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in c:\\users\\arooj zahra\\anaconda3\\envs\\gpu_env\\lib\\site-packages (from datasets->trl==0.7.4) (0.70.16)\n",
      "Requirement already satisfied: aiohttp in c:\\users\\arooj zahra\\anaconda3\\envs\\gpu_env\\lib\\site-packages (from datasets->trl==0.7.4) (3.11.12)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in c:\\users\\arooj zahra\\anaconda3\\envs\\gpu_env\\lib\\site-packages (from aiohttp->datasets->trl==0.7.4) (2.4.6)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\arooj zahra\\anaconda3\\envs\\gpu_env\\lib\\site-packages (from aiohttp->datasets->trl==0.7.4) (1.3.2)\n",
      "Requirement already satisfied: async-timeout<6.0,>=4.0 in c:\\users\\arooj zahra\\anaconda3\\envs\\gpu_env\\lib\\site-packages (from aiohttp->datasets->trl==0.7.4) (5.0.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\arooj zahra\\anaconda3\\envs\\gpu_env\\lib\\site-packages (from aiohttp->datasets->trl==0.7.4) (25.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\arooj zahra\\anaconda3\\envs\\gpu_env\\lib\\site-packages (from aiohttp->datasets->trl==0.7.4) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\arooj zahra\\anaconda3\\envs\\gpu_env\\lib\\site-packages (from aiohttp->datasets->trl==0.7.4) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in c:\\users\\arooj zahra\\anaconda3\\envs\\gpu_env\\lib\\site-packages (from aiohttp->datasets->trl==0.7.4) (0.2.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in c:\\users\\arooj zahra\\anaconda3\\envs\\gpu_env\\lib\\site-packages (from aiohttp->datasets->trl==0.7.4) (1.18.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\arooj zahra\\anaconda3\\envs\\gpu_env\\lib\\site-packages (from requests->transformers>=4.18.0->trl==0.7.4) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\arooj zahra\\anaconda3\\envs\\gpu_env\\lib\\site-packages (from requests->transformers>=4.18.0->trl==0.7.4) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\arooj zahra\\anaconda3\\envs\\gpu_env\\lib\\site-packages (from requests->transformers>=4.18.0->trl==0.7.4) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\arooj zahra\\anaconda3\\envs\\gpu_env\\lib\\site-packages (from requests->transformers>=4.18.0->trl==0.7.4) (2025.1.31)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\arooj zahra\\anaconda3\\envs\\gpu_env\\lib\\site-packages (from rich>=11.1.0->tyro>=0.5.11->trl==0.7.4) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\arooj zahra\\anaconda3\\envs\\gpu_env\\lib\\site-packages (from rich>=11.1.0->tyro>=0.5.11->trl==0.7.4) (2.19.1)\n",
      "Requirement already satisfied: importlib_metadata>=3.6 in c:\\users\\arooj zahra\\anaconda3\\envs\\gpu_env\\lib\\site-packages (from typeguard>=4.0.0->tyro>=0.5.11->trl==0.7.4) (8.6.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\arooj zahra\\anaconda3\\envs\\gpu_env\\lib\\site-packages (from jinja2->torch>=1.4.0->trl==0.7.4) (2.1.5)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\arooj zahra\\anaconda3\\envs\\gpu_env\\lib\\site-packages (from pandas->datasets->trl==0.7.4) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\arooj zahra\\anaconda3\\envs\\gpu_env\\lib\\site-packages (from pandas->datasets->trl==0.7.4) (2025.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\arooj zahra\\anaconda3\\envs\\gpu_env\\lib\\site-packages (from pandas->datasets->trl==0.7.4) (2025.1)\n",
      "Requirement already satisfied: zipp>=3.20 in c:\\users\\arooj zahra\\anaconda3\\envs\\gpu_env\\lib\\site-packages (from importlib_metadata>=3.6->typeguard>=4.0.0->tyro>=0.5.11->trl==0.7.4) (3.21.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\arooj zahra\\anaconda3\\envs\\gpu_env\\lib\\site-packages (from markdown-it-py>=2.2.0->rich>=11.1.0->tyro>=0.5.11->trl==0.7.4) (0.1.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\arooj zahra\\anaconda3\\envs\\gpu_env\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->datasets->trl==0.7.4) (1.17.0)\n",
      "Downloading trl-0.7.4-py3-none-any.whl (133 kB)\n",
      "Downloading tyro-0.9.16-py3-none-any.whl (117 kB)\n",
      "Downloading docstring_parser-0.16-py3-none-any.whl (36 kB)\n",
      "Downloading shtab-1.7.1-py3-none-any.whl (14 kB)\n",
      "Downloading typeguard-4.4.2-py3-none-any.whl (35 kB)\n",
      "Installing collected packages: shtab, docstring-parser, typeguard, tyro, trl\n",
      "  Attempting uninstall: trl\n",
      "    Found existing installation: trl 0.15.1\n",
      "    Uninstalling trl-0.15.1:\n",
      "      Successfully uninstalled trl-0.15.1\n",
      "Successfully installed docstring-parser-0.16 shtab-1.7.1 trl-0.7.4 typeguard-4.4.2 tyro-0.9.16\n"
     ]
    }
   ],
   "source": [
    "!pip install -U trl==0.7.4 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Arooj zahra\\AppData\\Local\\Temp\\ipykernel_1472\\901489568.py:2: FutureWarning: `tokenizer` is deprecated and removed starting from version 0.16.0 for `SFTTrainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = SFTTrainer(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "83da56bc9e06430b84f8e67a9879db86",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Converting train dataset to ChatML:   0%|          | 0/900 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a3e5fa999bfa403a962678d5ab2720bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Applying chat template to train dataset:   0%|          | 0/900 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa3df7a8f9cd4ef1b500dd9ff2357609",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Tokenizing train dataset:   0%|          | 0/900 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a1793dadd96e435b990b0dd26bd3e197",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Tokenizing train dataset:   0%|          | 0/900 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b4ed74e5d3cb46f9ab5859151884bebe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Converting eval dataset to ChatML:   0%|          | 0/100 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d9a2306e1ad74532a1ce2867de3af182",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Applying chat template to eval dataset:   0%|          | 0/100 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "892edbdda3bd4e88bae8a2de16866c57",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Tokenizing eval dataset:   0%|          | 0/100 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0da355c6735f4621ad063b00ed9bc6fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Tokenizing eval dataset:   0%|          | 0/100 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Most basic configuration that should work across versions\n",
    "trainer = SFTTrainer(\n",
    "    model=model,\n",
    "    train_dataset=dataset[\"train\"],\n",
    "    eval_dataset=dataset[\"test\"],\n",
    "    tokenizer=tokenizer,\n",
    "    args=training_arguments,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='450' max='450' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [450/450 11:17, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=450, training_loss=0.0, metrics={'train_runtime': 680.3764, 'train_samples_per_second': 1.323, 'train_steps_per_second': 0.661, 'total_flos': 9321084337895424.0, 'train_loss': 0.0})"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ensure tokenizer has a padding token\n",
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.pad_token = tokenizer.eos_token  # or use `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`\n",
    "\n",
    "# Resize model embeddings if new tokens were added\n",
    "model.resize_token_embeddings(len(tokenizer))\n",
    "\n",
    "# Now start training\n",
    "trainer.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Empty 'data_files': ''. It should be either non-empty or None (default).",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[80], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mdatasets\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m load_dataset\n\u001b[0;32m      3\u001b[0m dataset_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m----> 4\u001b[0m dataset \u001b[38;5;241m=\u001b[39m \u001b[43mload_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtext\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata_files\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdataset_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msplit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtrain\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(dataset)\n",
      "File \u001b[1;32mc:\\Users\\Arooj zahra\\anaconda3\\envs\\gpu_env\\lib\\site-packages\\datasets\\load.py:2110\u001b[0m, in \u001b[0;36mload_dataset\u001b[1;34m(path, name, data_dir, data_files, split, cache_dir, features, download_config, download_mode, verification_mode, keep_in_memory, save_infos, revision, token, streaming, num_proc, storage_options, trust_remote_code, **config_kwargs)\u001b[0m\n\u001b[0;32m   1926\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Load a dataset from the Hugging Face Hub, or a local dataset.\u001b[39;00m\n\u001b[0;32m   1927\u001b[0m \n\u001b[0;32m   1928\u001b[0m \u001b[38;5;124;03mYou can find the list of datasets on the [Hub](https://huggingface.co/datasets) or with [`huggingface_hub.list_datasets`].\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2107\u001b[0m \u001b[38;5;124;03m```\u001b[39;00m\n\u001b[0;32m   2108\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   2109\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m data_files \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m data_files:\n\u001b[1;32m-> 2110\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEmpty \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata_files\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m: \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdata_files\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m. It should be either non-empty or None (default).\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   2111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m Path(path, config\u001b[38;5;241m.\u001b[39mDATASET_STATE_JSON_FILENAME)\u001b[38;5;241m.\u001b[39mexists():\n\u001b[0;32m   2112\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   2113\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou are trying to load a dataset that was saved using `save_to_disk`. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2114\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease use `load_from_disk` instead.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2115\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: Empty 'data_files': ''. It should be either non-empty or None (default)."
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset_path = \"\"\n",
    "dataset = load_dataset(\"text\", data_files=dataset_path, split=\"train\")\n",
    "\n",
    "print(dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'get_chat_template' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[41], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m tokenizer \u001b[38;5;241m=\u001b[39m \u001b[43mget_chat_template\u001b[49m(\n\u001b[0;32m      2\u001b[0m     tokenizer,\n\u001b[0;32m      3\u001b[0m     chat_template \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mllama-3.1\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m      4\u001b[0m )\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mformatting_prompts_func\u001b[39m(examples):\n\u001b[0;32m      7\u001b[0m     convos \u001b[38;5;241m=\u001b[39m examples[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconversations\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "\u001b[1;31mNameError\u001b[0m: name 'get_chat_template' is not defined"
     ]
    }
   ],
   "source": [
    "tokenizer = get_chat_template(\n",
    "    tokenizer,\n",
    "    chat_template = \"llama-3.1\",\n",
    ")\n",
    "\n",
    "def formatting_prompts_func(examples):\n",
    "    convos = examples[\"conversations\"]\n",
    "    texts = [tokenizer.apply_chat_template(convo, tokenize = False, add_generation_prompt = False) for convo in convos]\n",
    "    return { \"text\" : texts, }\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "D:\\AroojZahra_Project\\llama model\\data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_cpp import Llama\n",
    "\n",
    "llm = Llama(model_path=\"./llama3.gguf\")\n",
    "response = llm(\"Summarize this document: ...\")\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastapi import FastAPI\n",
    "from llama_cpp import Llama\n",
    "\n",
    "app = FastAPI()\n",
    "llm = Llama(model_path=\"./llama3.gguf\")\n",
    "\n",
    "@app.post(\"/generate\")\n",
    "async def generate(prompt: str):\n",
    "    response = llm(prompt, max_tokens=100)\n",
    "    return {\"response\": response[\"choices\"][0][\"text\"]}\n",
    "\n",
    "# Run server: uvicorn filename:app --reload\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpu_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
